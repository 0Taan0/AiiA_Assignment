{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"color: orange;\">6. Modeling of Data: Transformers</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Finbert Sentiment 5 Epochs***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will cover the ahmedrachid/FinancialBERT-Sentiment-Analysis model. This model is a FineBERT model with a focus on sentiment analysis. This is interesting based on the sentiment analysis done in the data exploration, where the sentiment was overly positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 19:39:34.630412: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-25 19:39:34.669757: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-25 19:39:34.669787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-25 19:39:34.669811: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 19:39:34.678167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-25 19:39:35.741962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReceiverID</th>\n",
       "      <th>ActionType</th>\n",
       "      <th>NegoOutcome</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Length</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>Word_Count_nltk</th>\n",
       "      <th>NegoOutcomeLabel</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentCategory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SenderID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>Offer</td>\n",
       "      <td>FinalAccept</td>\n",
       "      <td>hope well management company agreed building f...</td>\n",
       "      <td>2529</td>\n",
       "      <td>17</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalAccept</td>\n",
       "      <td>reaching mei apologize slight delay getting ba...</td>\n",
       "      <td>2579</td>\n",
       "      <td>21</td>\n",
       "      <td>483</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165002</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalAccept</td>\n",
       "      <td>r kind response need hurry guess face daily fi...</td>\n",
       "      <td>2336</td>\n",
       "      <td>15</td>\n",
       "      <td>454</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222533</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalAccept</td>\n",
       "      <td>swift reply read set proposal discussed collea...</td>\n",
       "      <td>1961</td>\n",
       "      <td>13</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalAccept</td>\n",
       "      <td>proposal effort far seems getting close resolv...</td>\n",
       "      <td>1917</td>\n",
       "      <td>10</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>856</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>latest offer point completely let u take corpo...</td>\n",
       "      <td>1755</td>\n",
       "      <td>21</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>851</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>much latest offer happy could already reached ...</td>\n",
       "      <td>1460</td>\n",
       "      <td>17</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282807</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>856</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>meyer fast answer happy found solution issue n...</td>\n",
       "      <td>673</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>851</td>\n",
       "      <td>Counteroffer</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>still interested coming joint result neverthel...</td>\n",
       "      <td>969</td>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>856</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>FinalReject</td>\n",
       "      <td>sorry accept less understand argument like las...</td>\n",
       "      <td>276</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056771</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2332 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ReceiverID    ActionType  NegoOutcome  \\\n",
       "SenderID                                          \n",
       "70                69         Offer  FinalAccept   \n",
       "69                70  Counteroffer  FinalAccept   \n",
       "70                69  Counteroffer  FinalAccept   \n",
       "69                70  Counteroffer  FinalAccept   \n",
       "70                69  Counteroffer  FinalAccept   \n",
       "...              ...           ...          ...   \n",
       "851              856  Counteroffer  FinalReject   \n",
       "856              851  Counteroffer  FinalReject   \n",
       "851              856  Counteroffer  FinalReject   \n",
       "856              851  Counteroffer  FinalReject   \n",
       "851              856   FinalReject  FinalReject   \n",
       "\n",
       "                                                    Content  Content_Length  \\\n",
       "SenderID                                                                      \n",
       "70        hope well management company agreed building f...            2529   \n",
       "69        reaching mei apologize slight delay getting ba...            2579   \n",
       "70        r kind response need hurry guess face daily fi...            2336   \n",
       "69        swift reply read set proposal discussed collea...            1961   \n",
       "70        proposal effort far seems getting close resolv...            1917   \n",
       "...                                                     ...             ...   \n",
       "851       latest offer point completely let u take corpo...            1755   \n",
       "856       much latest offer happy could already reached ...            1460   \n",
       "851       meyer fast answer happy found solution issue n...             673   \n",
       "856       still interested coming joint result neverthel...             969   \n",
       "851       sorry accept less understand argument like las...             276   \n",
       "\n",
       "          Sentence_Count  Word_Count_nltk  NegoOutcomeLabel  Sentiment  \\\n",
       "SenderID                                                                 \n",
       "70                    17              470                 1   0.213699   \n",
       "69                    21              483                 1   0.165002   \n",
       "70                    15              454                 1   0.222533   \n",
       "69                    13              381                 1   0.160333   \n",
       "70                    10              376                 1   0.122500   \n",
       "...                  ...              ...               ...        ...   \n",
       "851                   21              358                 0   0.285340   \n",
       "856                   17              294                 0   0.282807   \n",
       "851                   10              144                 0   0.251786   \n",
       "856                    9              191                 0   0.163158   \n",
       "851                    5               60                 0   0.056771   \n",
       "\n",
       "         SentimentCategory  \n",
       "SenderID                    \n",
       "70                Positive  \n",
       "69                Positive  \n",
       "70                Positive  \n",
       "69                Positive  \n",
       "70                Positive  \n",
       "...                    ...  \n",
       "851               Positive  \n",
       "856               Positive  \n",
       "851               Positive  \n",
       "856               Positive  \n",
       "851               Positive  \n",
       "\n",
       "[2332 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Dataframe\n",
    "df = pd.read_excel('df_complete_cleansing.xlsx', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerverting Content to string\n",
    "df['Content'] = df['Content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the sentences and labels from the dataframe\n",
    "sentences = df['Content'].tolist()\n",
    "labels = df['NegoOutcomeLabel'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ahmedrachid/FinancialBERT-Sentiment-Analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the model name to be used\n",
    "model_name = \"ahmedrachid/FinancialBERT-Sentiment-Analysis\"\n",
    "\n",
    "# Load the tokenizer from the pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the pre-trained model for sequence classification with 2 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input sentences\n",
    "tokenized_texts = tokenizer(\n",
    "    sentences, max_length=512, truncation=True, padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(tokenized_texts[0])\n",
    "print(tokenized_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the input IDs from the tokenized texts\n",
    "input_ids = tokenized_texts[\"input_ids\"]\n",
    "\n",
    "# Extract the attention masks from the tokenized texts\n",
    "attention_masks = tokenized_texts[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input IDs and labels into training and validation sets with test size of 30%\n",
    "train_inputs, validation_inputs, train_labels, validation_labels= train_test_split(input_ids, labels, random_state=42, test_size=0.3)\n",
    "\n",
    "# Split the attention masks into training and validation sets\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    3,  8547, 19810,  ...,     0,     0,     0],\n",
       "        [    3,  1464,  3189,  ...,     0,     0,     0],\n",
       "        [    3,  6783,   949,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    3, 14153,   406,  ...,     0,     0,     0],\n",
       "        [    3,  6062,  1656,  ...,     0,     0,     0],\n",
       "        [    3,   787,  7594,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   3, 8547, 4640,  ...,    0,    0,    0],\n",
       "        [   3, 8547, 1665,  ...,    0,    0,    0],\n",
       "        [   3, 2124, 1512,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   3, 4815,  903,  ...,    0,    0,    0],\n",
       "        [   3, 4640, 6784,  ...,    0,    0,    0],\n",
       "        [   3, 5427,  135,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input IDs and labels into PyTorch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "#convert the attention masks into PyTorch tensors\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batchsize for training\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader for the training data with the specified batch size\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler=RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create a DataLoader for the validation data with the specified batch size\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler=SequentialSampler(validation_data)\n",
    "validation_dataloader =DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the selected device (GPU or CPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the selected device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the AdamW optimizer with the model parameters and a learning rate of 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the accuracy of the model\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Initialize counters for correct predictions and total examples\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        # Iterate over batches in the data loader\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            # Prepare data by moving input IDs, attention masks, and labels to the device (GPU or CPU)\n",
    "            input_ids, input_mask, labels = [t.to(device) for t in batch]  # Move to GPU\n",
    "\n",
    "            # Perform a forward pass through the model\n",
    "            outputs = model(input_ids, attention_mask=input_mask, labels=labels)\n",
    "            loss, logits = outputs['loss'], outputs['logits']\n",
    "\n",
    "            # Get the predicted labels by finding the index of the max logit\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            # Update the total number of examples and correct predictions\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "\n",
    "    # Calculate and return the accuracy as a percentage\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0005 | Batch 0000/0051 | Loss: 0.6509\n",
      "training accuracy: 68.50%\n",
      "valid accuracy: 69.43%\n",
      "Time elapsed: 1.10 min\n",
      "Epoch: 0002/0005 | Batch 0000/0051 | Loss: 0.6732\n",
      "training accuracy: 83.03%\n",
      "valid accuracy: 71.43%\n",
      "Time elapsed: 2.19 min\n",
      "Epoch: 0003/0005 | Batch 0000/0051 | Loss: 0.5174\n",
      "training accuracy: 95.28%\n",
      "valid accuracy: 71.00%\n",
      "Time elapsed: 3.28 min\n",
      "Epoch: 0004/0005 | Batch 0000/0051 | Loss: 0.2183\n",
      "training accuracy: 97.92%\n",
      "valid accuracy: 69.14%\n",
      "Time elapsed: 4.38 min\n",
      "Epoch: 0005/0005 | Batch 0000/0051 | Loss: 0.2950\n",
      "training accuracy: 99.26%\n",
      "valid accuracy: 72.43%\n",
      "Time elapsed: 5.48 min\n",
      "Total Training Time: 5.48 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time of the training process\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the number of training epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Loop over each batch in the training data loader\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # Prepare data by moving input IDs, attention masks, and labels to the device (GPU or CPU)\n",
    "        input_ids, input_mask, labels = [t.to(device) for t in batch]  \n",
    "        \n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=input_mask, labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "    \n",
    "        # Perform backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log the training progress every 250 batches\n",
    "        if not batch_idx % 250:\n",
    "            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
    "                   f'Batch {batch_idx:04d}/{len(train_dataloader):04d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "            \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Compute and print the training and validation accuracy\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_dataloader, device):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, validation_dataloader, device):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training progress is different compared to FinBERT, with the accuracies rising starting from epoch 2 and then showing signs of overfitting, with the training accuracy being very high and the validation accuracy remaining stagnant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Counts:\n",
      "Class 1: 585 predictions\n",
      "Class 0: 115 predictions\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.59      0.32      0.41       214\n",
      "     Class 1       0.75      0.90      0.82       486\n",
      "\n",
      "    accuracy                           0.72       700\n",
      "   macro avg       0.67      0.61      0.62       700\n",
      "weighted avg       0.70      0.72      0.70       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# After training, set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store all predictions and labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    # Iterate over batches in the validation data loader\n",
    "    for batch in validation_dataloader:\n",
    "       # Prepare data by moving input IDs, attention masks, and labels to the device (GPU or CPU)\n",
    "        input_ids, input_mask, labels = [t.to(device) for t in batch]\n",
    "        \n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=input_mask)\n",
    "        logits = outputs.logits  \n",
    "        \n",
    "        # Collect predictions and labels\n",
    "        predictions = torch.argmax(logits, dim=1)  \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Count the number of predictions for each class\n",
    "prediction_counts = Counter(all_predictions)\n",
    "print(\"\\nPrediction Counts:\")\n",
    "for label, count in prediction_counts.items():\n",
    "    print(f\"Class {label}: {count} predictions\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=[\"Class 0\", \"Class 1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is worse compared to the other models, especially in the Class 0 prediction. This could be due to overfitting or an unfavorable train-test split. However, this is in line with our sentiment analysis, which shows that the sentiment does not have a significant difference between accepted and rejected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been successfully saved:evaluation_finbert_sentiment_5_epochs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# After training, set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Initialize lists to store all predictions and labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    # Iterate over batches in the validation data loader\n",
    "    for batch in validation_dataloader:\n",
    "        # Prepare data by moving input IDs, attention masks, and labels to the device (GPU or CPU)\n",
    "        input_ids, input_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=input_mask)\n",
    "        logits = outputs.logits \n",
    "\n",
    "        # Collect predictions and labels\n",
    "        predictions = torch.argmax(logits, dim=1)  \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Count the predictions\n",
    "prediction_counts = Counter(all_predictions)\n",
    "\n",
    "# Classification report as dictionary\n",
    "classification_report_dict = classification_report(\n",
    "    all_labels, all_predictions, target_names=[\"Class 0\", \"Class 1\"], output_dict=True\n",
    ")\n",
    "\n",
    "# Prepare data \n",
    "result_data = {}\n",
    "\n",
    "# Add model name as the first column\n",
    "model_name = \"Finbert_Sentiment-5-epochs\"  \n",
    "result_data[\"Model\"] = [model_name]\n",
    "\n",
    "# Add prediction counts\n",
    "for label, count in prediction_counts.items():\n",
    "    result_data[f\"Prediction Count - Class {label}\"] = [count]\n",
    "\n",
    "# Add classification report\n",
    "for metric, values in classification_report_dict.items():\n",
    "    if isinstance(values, dict):\n",
    "        for sub_metric, value in values.items():\n",
    "            result_data[f\"{metric} - {sub_metric}\"] = [value]\n",
    "    else:\n",
    "        result_data[metric] = [values]\n",
    "\n",
    "# Create DataFrame \n",
    "result_df = pd.DataFrame(result_data)\n",
    "\n",
    "# Save as CSV\n",
    "result_df.to_csv(\"evaluation_results_finbert_sentiment_5_epochs.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been successfully saved:evaluation_finbert_sentiment_5_epochs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
